---
title: "Covid Surveys: Data Display and Aggregation"
output:
  rmdformats::html_clean
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dashdash)
```

# 1. Motivation

Lots of Covid-19 studies are going on. This tool can be used to present basic results in a simple manner in real time (or, as quickly as you can make your data available). 

Here's an example from Sierra Leone:  https://sl-dashboard.github.io/corona/

Besides helping you display data we have two ulterior motives:

* If teams use this it would be easy to use it to create a meta-dashboard across teams and countries making it easy to locate and view the good work being done
* If teams use this then it would not be hard to pool studies together to calculate cross study aggregates. In addition to the basic information, good aggregation woudl require sampling weights information.

Notes:

* **Software**: the dashboard is produced using `Rmarkdown` but the inputs are just data sets. If you work in stata or anything else and can produce `.dta` files (best to save as version 13 or below), `.csv` or `xls` it should be easy to input those to this set up. 

* **Modifying the software.** You can copy or fork the repository to modify it to suit your needs (pull requests also welcome!). The package contains very simple code. The main function is just a  call to `rmarkdown::render` to compile an `.Rmd` file. The `.Rmd` file pulls in some "child" `.Rmd`s. These `.Rmds` determine the overall stucture of the dashboard. For content, the `Rmd`s call to simple functions (e.g. `plot_aggregates()`)  that mostly implement calls to `dplyr` and `ggplot` to make tables and graphs. So edit the `.Rmd`s   (found in `\inst`) to modify the structure and edit the `.R`s (found in `\R`) to modify the analyses. 

* **Hosting**: If you can get the input files to us and can regularly upload your data to github we think we can produce and host the dashboard on this site and catalogue it with other ones. Alternatively the package produces a html file that you can host anywhere. If you have a Covid survey that you want to connect with this drop a note to `macartan.humphreys@wzb.eu` or `julio.solis@wzb.eu`.

* **Note on open source material**: All material here is open source. Data posted here will be made public and should not contain any personally identifiable information.

* **Workflow**: we are still figuring it out but we think we can set this up so that once the basic parameteres are set, periodic data can be provided via a pull request or a link to a repository and then the dashboard will automatically update.

# 2. Inputs

The dashboard function requires three key inputs:

## `my_vars` dataframe

A spreadsheet that says what your variables are and to which families they belong. For example:

```{r, echo = FALSE}
 my_vars <- data.frame(
   variable = c("market_open", "price_rice", "aware", "water"),
   family = c("Markets", "Markets", "Actions", "Actions"),
   short_label = c("Is market open?", "Price of a rice", "Aware of Covid19", "Access to water"),
   description = c("details on market open", "Price of a cup of rice", "Details on aware of Covid19", "Details on access to water"),
   min = c(-2, -1, 0, NA),
   stringsAsFactors = FALSE
 )

kable(my_vars, caption = "sample `my_vars` dataframe")

```

The short labels here appear on the figures and graphs and really should be short.

## `my_data`  dataframe

Your data, cleaned and transformed to the point where it is ready for display:

```{r, echo = FALSE}
my_data <-
   expand_grid(id = c("Bo", "Bombali", "Bonthe"), date = as.Date(c("2020-04-18", "2020-04-19", "2020-04-20"))) %>%
   data.frame(stringsAsFactors = FALSE) %>%
     mutate(n = 3) %>%
     uncount(n) %>%
     dplyr::mutate(
     market_open	 = rbinom(n(), 1, .5),
     price_rice	 = rbinom(n(), 1, .5),
     aware	 = rbinom(n(), 1, .5),
     water	 = rbinom(n(), 1, .5)) %>%
     distinct()

datatable(my_data, caption = "sample `my_data` dataframe")

```

The key requirements are that the dataset contains:

* an `id` variable which gives the level at which you want the data to be aggregated for averages -- this variable should correspond to your id variable in your shape files   
* a `date` variable whch is a string variable of the form `YYYY-MM-DD`

## `my_args`  dataframe

Third, a spreadsheet with dashboard specific arguments, inluding any text you want to appear. You can provide title and author information in here, or you can provide these directly to the dashboard function. 

```{r, echo = FALSE}

my_args <- data.frame(
  intro_text = "Intro text",
  intro_note = "Lots of great people worked on this. More information here: ...",
  data_note = "Study specific note about data source",
  map_path = paste0(getwd(), '/shapefiles'),
  map_layer = "SLE_adm3",
  map_region =  "NAME_2",
  group = "District",
  scale_vars = TRUE,
  stringsAsFactors = FALSE
)

my_args %>% kable(caption = "sample `my_args` dataframe")

```



# 3 Produce Dashboard

The dashboard is then produced by `dashdash::dashdash` like this:

```{r, message = FALSE, warning = FALSE, include = FALSE}

dashdash::dashdash(
  output_file = paste(getwd(), "example.html"),
  title = "A sample dashboard for my study",
  subtitle = "What's special about this study",
  my_data = my_data,
  my_vars = my_vars,
  my_args = my_args)

```

Note that `output_file`, `my_data`, `my_vars` and `my_args` are the only required inputs. In this example we also provide `title` and `subtitle` directly, but these could also be contained in `my_args`.


```{r, eval  = FALSE}

remotes::install_github("wzb-ipi/dashdash")

dashdash::dashdash(
  output_file = "example.html",
  title = "A sample dashboard for my study",
  subtitle = "What's special about this study",
  my_data = my_data,
  my_vars = my_vars,
  my_args = my_args)

```

You can then view it: [example.html](example.html)

# 4 Aggregating dashboards

Coming next
